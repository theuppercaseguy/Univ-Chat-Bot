{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install requests\n",
        "!pip -q install beautifulsoup4\n",
        "!pip -q install chromadb\n",
        "!pip -q install sentence_transformers\n",
        "!pip -q install langchain\n",
        "!pip -q install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfjBVgfFGjxB",
        "outputId": "fc8b31df-3c31-42a0-c30a-50636bacf171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.0/399.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for chroma-hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Scrapping**"
      ],
      "metadata": {
        "id": "TFCHD9i3Xgkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_website(url):\n",
        "    # Send an HTTP GET request to the website\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Parse the HTML content using BeautifulSoup\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Extract the main content of the website (e.g., paragraphs, headings, etc.)\n",
        "        main_content = soup.get_text()\n",
        "\n",
        "        return main_content\n",
        "    else:\n",
        "        print(f\"Failed to fetch the website. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "def save_to_text_file(content, filename):\n",
        "    with open(filename, 'a', encoding='utf-8') as file:\n",
        "        file.write(content)\n",
        "\n",
        "# List of URLs of websites to scrape\n",
        "website_urls = [\n",
        "    # \"https://admissions.giki.edu.pk/?_gl=1*1rf8fts*_ga*MTkwMTQ2MTgyOS4xNjkwMzczNzE5*_ga_0V1VCVDDMJ*MTY5MDM3MzcxOC4xLjAuMTY5MDM3MzcxOC4wLjAuMA..*_gcl_au*MTE2MjY4ODExOC4xNjkwMzczNzE5*_ga_8XS4Z2GJ4Z*MTY5MDM3MzcyMC4xLjAuMTY5MDM3MzcyMC4wLjAuMA..&_ga=2.252256394.2069371705.1690373720-1901461829.1690373719\",\n",
        "    \"https://giki.edu.pk/admissions/admissions-undergraduates/ugrad-fees-and-expenses/\",\n",
        "    \"https://giki.edu.pk/admissions/admissions-undergraduates/ugradhow-to-apply/\"\n",
        "]\n",
        "#website_urls = List[:200]\n",
        "# Name of the text file to store the scraped content\n",
        "filename = \"scrapped_Data.txt\"\n",
        "\n",
        "# Scrape the websites and save the content to the text file\n",
        "for url in website_urls:\n",
        "    website_content = scrape_website(url)\n",
        "    if website_content:\n",
        "        save_to_text_file(website_content, filename)\n",
        "\n",
        "print(f\"All website content has been saved to '{filename}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXp6q5YSGkcH",
        "outputId": "e65584fd-9139-4d82-cfcc-76ea650009b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All website content has been saved to 'scrapped_Data.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jIyamcj67bBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1O7C97-sXkH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instentiaiting langchaing"
      ],
      "metadata": {
        "id": "gSBfFNFbXlMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0aSmYoCtXlA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain import HuggingFaceHub\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.document_loaders import TextLoader\n",
        "import os\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "with open(\"cleanScrape.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    content = file.read()\n",
        "\n",
        "loader = TextLoader(\"scrapped_Data.txt\")\n",
        "docs = loader.load()\n",
        "#docs = content\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "docs= text_splitter.split_documents(docs)\n",
        "\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
        "embeddings = HuggingFaceEmbeddings()\n",
        "\n",
        "\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain import HuggingFaceHub\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "\n",
        "\n",
        "docsearch = Chroma(persist_directory=\"chroma_db\", embedding_function=embeddings)\n",
        "repo_id=\"google/flan-t5-base\"\n",
        "qa = ConversationalRetrievalChain.from_llm(\n",
        "    llm = HuggingFaceHub( repo_id=repo_id, model_kwargs={\"temperature\": 0, \"max_length\":512}),\n",
        "    retriever=docsearch.as_retriever(),\n",
        "    return_source_documents=True,\n",
        "  )\n",
        "\n",
        "import sys\n",
        "history = []\n",
        "\n"
      ],
      "metadata": {
        "id": "JiEteXspUQ2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2KoHpoVEXuGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating FAST API**"
      ],
      "metadata": {
        "id": "qcFprIfDXurO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=['*'],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=['*'],\n",
        "    allow_headers=['*'],\n",
        ")\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "  return {\"Tesitng\":\"localhost/chat_me/Your query\", \"data\":99}\n",
        "\n",
        "@app.get(\"/chat_me/{query}\")\n",
        "async def get_data(query):\n",
        "\n",
        "    result = qa({'question': query, 'chat_history': history})\n",
        "    #print('Ans: ' + result['answer'])\n",
        "    history.append((query, result['answer']))\n",
        "\n",
        "    data = open(f\"./history.txt\", \"a\")\n",
        "    data.write(\"Q: \" + query + \". ANS: \" + history[-1][1] + \"\\n\")  # Write the last answer in the history\n",
        "    data.close()\n",
        "\n",
        "    return {\"answere\": result['answer']}"
      ],
      "metadata": {
        "id": "jevtfoRGUQzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gvL0xwj3UvHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using NGROK to serve it"
      ],
      "metadata": {
        "id": "HIeKS0QWXyP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ],
      "metadata": {
        "id": "GqMiBWFdUQw2",
        "outputId": "b21aaf9a-0450-46c4-8111-f4864409c5ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-07-31T09:48:42+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://e4df-34-86-184-30.ngrok.io\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [149]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     182.180.143.221:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     182.180.143.221:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     103.163.238.68:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     182.180.143.221:0 - \"GET /chat_me/list%20all%20the%20scholarships HTTP/1.1\" 200 OK\n",
            "INFO:     182.180.143.221:0 - \"GET /chat_me/list%20all%20the%20scholarships HTTP/1.1\" 200 OK\n",
            "INFO:     182.180.143.221:0 - \"GET /chat_me/chat_me/scholarships HTTP/1.1\" 404 Not Found\n",
            "INFO:     103.11.1.4:0 - \"GET /chat_me/chat_me/scholarships HTTP/1.1\" 404 Not Found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bf36yqx4UQuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tr_LiLnhUQr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "axjKGNK5UQa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UF9ch7NmUQaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sl4xx5WsUQYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AFZaYFzwUQXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fQ4ACcCnUQV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FnHze3EmUQUQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}